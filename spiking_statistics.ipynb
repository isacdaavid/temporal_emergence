{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5b09300f1aaa29f91518898d289bfe7c6a13e39f5c39de69ed81889dba9d5a76"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "736\n",
      "binarised the trains\n",
      "ipykernel_launcher:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n",
      "binarised the trains\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb955b404ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinsizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbinsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinsizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmin_occ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPMMaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_state_occurrences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_BITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# keep skip at 0, it's not actually used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mmin_num_occurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_occ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - Monash University/Year 3/Semester 1/FIT3144/Temporal_emergence_analysis/temporal_emergence.py\u001b[0m in \u001b[0;36mget_num_state_occurrences\u001b[0;34m(spiketrains, S, K, skipby)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mi_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPMMaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_TPM_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mnum_transitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_c\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnum_transitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### COMPUTE MIN NUMBER OF STATE OCCURRENCES in each BIDIRECTIONALLY CONNECTED pair ### \n",
    "from temporal_emergence import TPMMaker \n",
    "import numpy as np\n",
    "folder = \"GLMCC/Cori_2016-12-14_probe1\"\n",
    "\n",
    "### OBTAIN BIDIRECTIONALLY CONNECTED NEURONS ### \n",
    "\n",
    "probe1_371 = np.loadtxt(\"results/connectivity_Cori_2016-12-14_probe1/W_py_5400.csv\", delimiter=\",\")\n",
    "\n",
    "# get tuples of connected neurons\n",
    "ai,bi = np.where(abs(probe1_371) != 0)\n",
    "index_pairs = list(zip(ai,bi))\n",
    "\n",
    "bidirectionally = []\n",
    "for (r,t) in index_pairs:\n",
    "    if (t,r) in index_pairs and (t,r) not in bidirectionally:\n",
    "        bidirectionally.append((r,t))\n",
    "\n",
    "### COMPUTE MIN OCCURRENCES ### \n",
    "### PARAMETERS ###\n",
    "\n",
    "NUM_BITS = 2\n",
    "\n",
    "max_binsize = 0.02  # 20 ms bins\n",
    "min_binsize = 0.0029 # skip 1ms bins  -   never work and are very slow to compute\n",
    "num_binsizes = 9\n",
    "binsizes = np.linspace(min_binsize, max_binsize, num_binsizes)\n",
    "\n",
    "min_num_occurrences = np.zeros((len(bidirectionally), len(binsizes)))\n",
    "\n",
    "\n",
    "for p in range(len(bidirectionally)):\n",
    "    i,j = bidirectionally[p]\n",
    "    ### LOAD DATASET ###\n",
    "\n",
    "    i_sec = np.loadtxt(folder + \"/cell\" + str(i) + \".txt\") / 1000   # divide through as they are loaded in seconds\n",
    "    j_sec = np.loadtxt(folder + \"/cell\" + str(j) + \".txt\") / 1000\n",
    "    cluster = np.array([i_sec, j_sec])\n",
    "\n",
    "    ### LOOP THROUGH PARAMETERS, computing min of state occurrences ###\n",
    "    for k in range(len(binsizes)):\n",
    "        binsize = binsizes[k]\n",
    "        min_occ = np.min(TPMMaker.get_num_state_occurrences(cluster,binsize, NUM_BITS, 0))   # keep skip at 0, it's not actually used\n",
    "        min_num_occurrences[p,k] = min_occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET THE PHIS FOR A PARTICULAR NEURON PAIR\n",
    "import numpy as np\n",
    "def get_phis(num_transitions, outfolder):\n",
    "\n",
    "    ### COMPUTE PHIS ###\n",
    "\n",
    "    micro_phis = np.zeros((len(binsizes), len(skips)))\n",
    "    macro_phis = np.zeros((len(binsizes), len(skips)))\n",
    "\n",
    "    for i in range(len(binsizes)):\n",
    "        binsize = binsizes[i]\n",
    "        for j in range(len(skips)):\n",
    "            skip = skips[j]\n",
    "\n",
    "            try:\n",
    "                TPM,_ = TPMMaker.TPM_from_spiketrains(cluster,binsize,NUM_BITS,skip,num_transitions)\n",
    "                tpmname = \"micro_\" + str(i) + \"_\" + str(j) + \"_occs_\" + str(num_transitions) + \"_bin_\"+str(binsize)+\"_skip_\"+str(skip)+\".csv\" \n",
    "                np.savetxt(outfolder+\"/\"+tpmname, TPM)\n",
    "                success = True\n",
    "            except:\n",
    "                success = False\n",
    "                print(\"Failed for binsize: \" + str(binsize) + \" and skip: \" + str(skip))\n",
    "            \n",
    "            if success:\n",
    "                micro_phis[i,j] = PhiCalculator.get_micro_average_phi(TPM, verbose=False)\n",
    "                macro_phis[i,j] = PhiCalculator.get_macro_average_phi(TPM, verbose=False)\n",
    "                print(\"Success for binsize: \" + str(binsize) + \" and skip: \" + str(skip))\n",
    "            \n",
    "            else:\n",
    "                micro_phis[i,j] = None\n",
    "                macro_phis[i,j] = None\n",
    "    \n",
    "    micro_phis = np.array(micro_phis, dtype=np.float64)\n",
    "    macro_phis = np.array(macro_phis, dtype=np.float64)\n",
    "    \n",
    "    max_micro = np.nanmax(micro_phis)\n",
    "    max_macro = np.nanmax(macro_phis)\n",
    "    macro_win = True if max_macro > max_micro else False\n",
    "\n",
    "    return macro_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR PAIR 143, 168, REPEATEDLY COMPUTE PHIS FOR DIFFERENT NUMBER OF MIN OCCURRENCES,\n",
    "### TO SEE PROPORTION OF MACRO WINS AT DIFFERENT NUMBERS OF MIN OCCURRENCES\n",
    "\n",
    "NUM_BITS = 2\n",
    "\n",
    "max_binsize = 0.02  # 20 ms bins\n",
    "min_binsize = 0.0029 # skip 1ms bins  -   never work and are very slow to compute\n",
    "num_binsizes = 9\n",
    "binsizes = np.linspace(min_binsize, max_binsize, num_binsizes)\n",
    "\n",
    "occurrences = range(100, 1100, 100)\n",
    "NUM_REPETITIONS = 100\n",
    "\n",
    "outfolder = \"TPM_143_168_varying_min_occs\"\n",
    "\n",
    "### REPEATEDLY COMPUTE PHIS AND SEE IF MACRO WINS, FOR VARIOUS MIN NUMBER OF REPETITIONS\n",
    "macro_wins = np.zeros((len(occurrences)))\n",
    "for i in range(len(occurrences)):\n",
    "    min_occurrence = occurrences[i]\n",
    "    for rep in range(NUM_REPETITIONS):\n",
    "        macro_win = get_phis(min_occurrence, outfolder)\n",
    "        if macro_win:\n",
    "            macro_wins[i] += 1\n",
    "\n",
    "macro_wins_pct = macro_wins / NUM_REPETITIONS\n"
   ]
  }
 ]
}